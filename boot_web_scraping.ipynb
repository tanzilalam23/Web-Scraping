{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6b2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # For collecting data\n",
    "import json # To create a JSON file\n",
    "import requests # For sending request to the server to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25da9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate median value\n",
    "\n",
    "def calculate_median(prices):\n",
    "    \"\"\"\n",
    "    Calculates the median value of a list of prices.\n",
    "\n",
    "    Parameters:\n",
    "    - prices (list of float): A list of numerical values representing prices.\n",
    "\n",
    "    Returns:\n",
    "    - float: The median value of the provided prices.\n",
    "    \"\"\"\n",
    "    sorted_prices = sorted(prices)\n",
    "    n = len(sorted_prices)\n",
    "\n",
    "    if n % 2 == 0:\n",
    "        median = (sorted_prices[n//2 - 1] + sorted_prices[n//2]) / 2\n",
    "    else:\n",
    "        median = sorted_prices[n//2]\n",
    "\n",
    "    return median\n",
    "\n",
    "\n",
    "# Use this function with a working URL\n",
    "def scrape_boots_website(url):\n",
    "    \"\"\"\n",
    "    Scrapes product information from the Boots website.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL of the Boots website page to be scraped.\n",
    "\n",
    "    Returns:\n",
    "    - BeautifulSoup: A BeautifulSoup object representing the parsed HTML content of the webpage.\n",
    "\n",
    "    Example:\n",
    "    >>> url = \"https://www.boots.com/health-pharmacy/medicines-treatments/sleep?paging.index=0&amp;paging.size=24&amp;sortBy=mostRelevant&amp;criteria.category=wellness---sleep&amp;criteria.brand=Bach+Rescue+Remedy---Boots\"\n",
    "    >>> soup = scrape_boots_website(url)\n",
    "    >>> # Countinue with Ln [4]\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5eef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give file name or path, depending on the location of your file\n",
    "file_path = 'orignal.html' \n",
    "\n",
    "# Read the contents of the HTML file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parsing the HTML content to extract different data's\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c0c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two list for storing respected values\n",
    "result_list = [] # For appending all the items\n",
    "prices = [] # For appending all the \"numeric_price\"\n",
    "\n",
    "# Fetching all the products information from the webpage\n",
    "products_items = soup.find_all('div', class_='oct-grid__row oct-grid__row--full-width oct-listers-hits')\n",
    "\n",
    "# Loop to find required item from the product list\n",
    "for item in products_items:\n",
    "    \n",
    "    # Finding Title from the products_items\n",
    "    try:\n",
    "        item_titles = item.find_all('h3', {'class': 'oct-text oct-text--standard oct-text--size_m oct-aem-text oct-aem-text--h3--variant-2 oct-teaser__title oct-teaser-with-listers'})\n",
    "    except:\n",
    "        print(\"\")\n",
    "        \n",
    "    # Finding Price from the products_items\n",
    "    try:\n",
    "        item_prices = item.find_all('p', {'class': 'oct-text oct-text--standard oct-text--size_m oct-aem-text oct-aem-text--p--variant-subtext oct-teaser__productPrice'})\n",
    "    except:\n",
    "        print(\"\")\n",
    "    \n",
    "    # Finding Offer from the products_items\n",
    "    try:\n",
    "        item_offer = item.find_all('div', {'class': 'oct-teaser__wrap'})\n",
    "    except:\n",
    "        print(\"\")\n",
    "\n",
    "    # Running a loop to capture information of each product     \n",
    "    for title, price, offer in zip(item_titles, item_prices, item_offer):\n",
    "        title_text = title.get_text(strip=True)\n",
    "        price_text = price.get_text(strip=True)\n",
    "        offer_text = offer.get_text(strip=True)\n",
    "        \n",
    "        # \"result_list\" accumulates these dictionaries for all products on the page \n",
    "        result_list.append({'Title': title_text, 'Price': price_text, 'Price_Unit': '£', 'Offer': offer_text})\n",
    "        \n",
    "        # Extract numerical prices for median calculation\n",
    "        numeric_price = float(price_text.replace('£', '').replace(',', ''))\n",
    "        prices.append(numeric_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f052aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median price\n",
    "median_price = calculate_median(prices)\n",
    "\n",
    "# Save the information in a JSON file\n",
    "output_data = {\n",
    "    'Products': result_list,\n",
    "    'Median': median_price\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f59f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the JSON file, named \"output.json\"\n",
    "with open('output.json', 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(output_data, output_file, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
